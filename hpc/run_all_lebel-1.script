#!/bin/bash
#SBATCH --job-name=n9
#SBATCH --time=16:00:00
#SBATCH --mem 150GB
#SBATCH --partition=parallel
#SBATCH --signal=USR2
#SBATCH --nodes=1
#SBATCH --cpus-per-task=8
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=karmeni1@jh.edu
#SBATCH --output=UTS02_run_all_n9.job.%j.out
#SBATCH --error=UTS02_run_all_n9.job.%j.err
# ---------------------------------------------------

ml anaconda3/2024.02-1
conda activate enc

source_dir="/data/choney1/karmeni1/enc/src"

# this will run 'huth_regression'
python  $source_dir/encoders/run_all.py \
--subject "UTS02" \
--predictor "all" \
--n_delays 5 \
--interpolation "lanczos" \
--n_train_stories 1 3 5 7 9 \
--strategy "simple" \
--n_repeats 15 \
--no_keep_train_stories_in_mem # don't keep data in memory to save memory usage
